{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-06-17 01:17:48--  https://drive.usercontent.google.com/download?id=1lhAaeQCmk2y440PmagA0KmIVBIysVMwu&export=download&authuser=0&confirm=t&uuid=3077628e-fc9b-4ef2-8cde-b291040afb30&at=APZUnTU9lSikCSe3NqbxV5MVad5T%3A1708243355040\n",
      "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 142.251.42.225, 2404:6800:4012:4::2001\n",
      "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|142.251.42.225|:443... ^C\n"
     ]
    }
   ],
   "source": [
    "!wget --header=\"Host: drive.usercontent.google.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7\" --header=\"Accept-Language: en-US,en;q=0.9,ar;q=0.8\" --header=\"Cookie: HSID=Ag2OIHvsd2Wub4C7z; SSID=AWnBcQKwDHiTrZAU1; APISID=pltrFZgE9lJ0o1gq/AN9feEHYvs8oHd519; SAPISID=zgF45F21ZPWzYWZw/AgUMJ8b7QQXuWGn19; __Secure-1PAPISID=zgF45F21ZPWzYWZw/AgUMJ8b7QQXuWGn19; __Secure-3PAPISID=zgF45F21ZPWzYWZw/AgUMJ8b7QQXuWGn19; SID=g.a000fwgYx1PcnW-rFyFhg3x6mQHzCrwXz-KFhoOLogUl7YTWI-uttBbVDRolhF-hY16nwHXw0gACgYKAWISAQASFQHGX2MivNTw_E_toJuIRy6LMpKNOBoVAUF8yKpFSmvq7AMjvEWeNc50Zff40076; __Secure-1PSID=g.a000fwgYx1PcnW-rFyFhg3x6mQHzCrwXz-KFhoOLogUl7YTWI-utbSY2jBY1VXuw8gYl5hIO2QACgYKAXsSAQASFQHGX2MihVCJ1PwLozGqZgdSatM9QhoVAUF8yKpgrsTvI8i_UE-YHpoN7Gx-0076; __Secure-3PSID=g.a000fwgYx1PcnW-rFyFhg3x6mQHzCrwXz-KFhoOLogUl7YTWI-utwVfPl2imdPimZJ9tdDZGQAACgYKAUESAQASFQHGX2MiEJ49mV4jME2kttDAV5hwWBoVAUF8yKp80mIgju1lu-q4nI7VsFDM0076; NID=511=efI9IZpxtyJ7Dw1MAUXU8FlzS5jXGewY4Er8HliWc3A0RSWdgvNDyKY66ETjgRyTGWPbWODSmiSeYSBab5SPHVwqbJxd6ZeGW2f6BkHi61UKksXPH0CVJRM1hKpMjHPU5qw7tboM2Mi87NrosV8COB-GCLulLLbjOoSAEQewTe8NVZ5Owq8IkwvxFGfJkmUKEMkFWrw9yb5nTDl3wbZEsGFI92iEdNTSxSRovNCIPN2US-SCFdQ0m2BtvwdiWZbgnn7dSQ8yPA145Kk2BA-ATpJNJ6SJHEHLQY-9CPail9D5qgJgxR925EUg5RGCpEu9wS5xbA62KTa19wAvbAq7Dk3TWc-iX4p1s7ESFyDC7yMpFxiFPJjqkWwFi_ZfiK2TW2t0TQ60DFBxqOytQaLyHrkEvD-CQPVj6OCOP22cZY0Cu61HaAQgFO9pXH-kJUlywzVdbirJumN5gswyaQ49b3KdLcG0Jb7brOMTM24T2nGtQ10hJzsnTwX7dBk3ujqQrI_DGuURvPassPUrIZ0; AEC=Ae3NU9MOEGeKAZjP6INpOYbyMraWAWztmx5pJB_1ILu1furiTy1K37k15u0; __Secure-1PSIDTS=sidts-CjEBYfD7Z9twEKTWJ9gU7KG-rLbxJGNRQIoG3wH6JVu6yiCC2fsRrm7tN8L6d5WlILrnEAA; __Secure-3PSIDTS=sidts-CjEBYfD7Z9twEKTWJ9gU7KG-rLbxJGNRQIoG3wH6JVu6yiCC2fsRrm7tN8L6d5WlILrnEAA; 1P_JAR=2024-02-18-08; SIDCC=ABTWhQExCxkfmwCkG1RaEgz8U1ZkPeh3HmLMUdMt8S5cNSsLY5U5rAL6wlvq7dtjRw7zrtAbqsFI; __Secure-1PSIDCC=ABTWhQH0jLeRIS6Tu3LS8DXB5Q3gGDq9LTmlk60FKu795Bf0UbzsOcYWVAE96clq5aAL8i724Q0; __Secure-3PSIDCC=ABTWhQHIFcyv3nZYwp78WXEQal71jCE_ZsGT5lXs8VLr7XDIfFqHcLTIPz4HxzJb9ZnYQ5l2s9eU\" --header=\"Connection: keep-alive\" \"https://drive.usercontent.google.com/download?id=1lhAaeQCmk2y440PmagA0KmIVBIysVMwu&export=download&authuser=0&confirm=t&uuid=3077628e-fc9b-4ef2-8cde-b291040afb30&at=APZUnTU9lSikCSe3NqbxV5MVad5T%3A1708243355040\" -c -O 'tennis_court_det_dataset.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip tennis_court_det_dataset.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 创建 Torch 数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class KeypointsDataset(Dataset):\n",
    "    def __init__(self, img_dir, data_file):\n",
    "        self.img_dir = img_dir\n",
    "        with open(data_file, \"r\") as f:\n",
    "            self.data = json.load(f)\n",
    "        \n",
    "        self.transforms = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        img = cv2.imread(f\"{self.img_dir}/{item['id']}.png\")\n",
    "        h,w = img.shape[:2]\n",
    "\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = self.transforms(img)\n",
    "        kps = np.array(item['kps']).flatten()\n",
    "        kps = kps.astype(np.float32)\n",
    "\n",
    "        kps[::2] *= 224.0 / w # Adjust x coordinates\n",
    "        kps[1::2] *= 224.0 / h # Adjust y coordinates\n",
    "\n",
    "        return img, kps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = 'datasets/tennis_court_det_dataset/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = KeypointsDataset(f\"{data_dir}/images\",f'{data_dir}/data_train.json')\n",
    "val_dataset = KeypointsDataset(f\"{data_dir}/images\",f'{data_dir}/data_val.json')\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creat model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torch\n",
    "\n",
    "# 设置环境变量 TORCH_MODEL_ZOO，指向国内镜像\n",
    "torch.hub.set_dir('./models')  # 更改缓存目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 修改预训练模型的下载地址\n",
    "model_urls = {\n",
    "    'resnet50': 'https://pytorch-1252820389.cos.ap-beijing.myqcloud.com/vision-0.6.0/resnet50-19c8e357.pth'\n",
    "}\n",
    "models.resnet.model_urls = model_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 加载模型\n",
    "model = models.resnet50(pretrained=True)\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, 14*2)  # 替换最后一层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_latest_model(directory):\n",
    "    model_files = [f for f in os.listdir(directory) if f.endswith('.pth')]\n",
    "    if not model_files:\n",
    "        return None\n",
    "    latest_model = max(model_files, key=lambda x: os.path.getmtime(os.path.join(directory, x)))\n",
    "    return os.path.join(directory, latest_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from ./models/keypoints_model_20240617_025338.pth\n"
     ]
    }
   ],
   "source": [
    "# 加载预训练的ResNet50模型结构\n",
    "model = models.resnet50(pretrained=False)\n",
    "\n",
    "# 获取目录下最新的模型文件\n",
    "latest_model_path = get_latest_model('./models')\n",
    "\n",
    "if latest_model_path:\n",
    "    # 加载本地下载的权重或最新模型\n",
    "    checkpoint = torch.load(latest_model_path)\n",
    "    # 替换最后一层\n",
    "    model.fc = torch.nn.Linear(model.fc.in_features, 14*2)  # 替换最后一层\n",
    "\n",
    "    model.load_state_dict(checkpoint)\n",
    "    print(f\"Loaded model from {latest_model_path}\")\n",
    "else:\n",
    "    # 如果没有找到模型文件，则加载预训练的权重\n",
    "    checkpoint = torch.load('./models/resnet50-0676ba61.pth')\n",
    "    # 替换最后一层\n",
    "    model.fc = torch.nn.Linear(model.fc.in_features, 14*2)  # 替换最后一层\n",
    "\n",
    "    model.load_state_dict(checkpoint)\n",
    "    print(\"Loaded pretrained weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, iter 0, loss: 14631.1796875\n",
      "Epoch 0, iter 10, loss: 14621.6171875\n",
      "Epoch 0, iter 20, loss: 16472.197265625\n",
      "Epoch 0, iter 30, loss: 14215.1728515625\n",
      "Epoch 0, iter 40, loss: 14041.837890625\n",
      "Epoch 0, iter 50, loss: 12637.451171875\n",
      "Epoch 0, iter 60, loss: 12077.29296875\n",
      "Epoch 0, iter 70, loss: 12076.869140625\n",
      "Epoch 0, iter 80, loss: 11818.9892578125\n",
      "Epoch 0, iter 90, loss: 11056.7333984375\n",
      "Epoch 0, iter 100, loss: 11302.1904296875\n",
      "Epoch 0, iter 110, loss: 12097.96484375\n",
      "Epoch 0, iter 120, loss: 10321.1904296875\n",
      "Epoch 0, iter 130, loss: 9755.6533203125\n",
      "Epoch 0, iter 140, loss: 10269.4091796875\n",
      "Epoch 0, iter 150, loss: 9652.9033203125\n",
      "Epoch 0, iter 160, loss: 8747.388671875\n",
      "Epoch 0, iter 170, loss: 8944.197265625\n",
      "Epoch 0, iter 180, loss: 8154.970703125\n",
      "Epoch 0, iter 190, loss: 7442.69921875\n",
      "Epoch 0, iter 200, loss: 7613.21337890625\n",
      "Epoch 0, iter 210, loss: 8226.5048828125\n",
      "Epoch 0, iter 220, loss: 6873.5048828125\n",
      "Epoch 0, iter 230, loss: 7065.41064453125\n",
      "Epoch 0, iter 240, loss: 6557.435546875\n",
      "Epoch 0, iter 250, loss: 6487.5986328125\n",
      "Epoch 0, iter 260, loss: 6279.443359375\n",
      "Epoch 0, iter 270, loss: 5771.84423828125\n",
      "Epoch 0, iter 280, loss: 5643.31982421875\n",
      "Epoch 0, iter 290, loss: 5478.29248046875\n",
      "Epoch 0, iter 300, loss: 5311.5810546875\n",
      "Epoch 0, iter 310, loss: 5129.9228515625\n",
      "Epoch 0, iter 320, loss: 4667.4736328125\n",
      "Epoch 0, iter 330, loss: 4376.1669921875\n",
      "Epoch 0, iter 340, loss: 4268.46630859375\n",
      "Epoch 0, iter 350, loss: 4179.21875\n",
      "Epoch 0, iter 360, loss: 4009.28271484375\n",
      "Epoch 0, iter 370, loss: 3571.30810546875\n",
      "Epoch 0, iter 380, loss: 3662.37939453125\n",
      "Epoch 0, iter 390, loss: 3525.144775390625\n",
      "Epoch 0, iter 400, loss: 3117.43212890625\n",
      "Epoch 0, iter 410, loss: 2971.136962890625\n",
      "Epoch 0, iter 420, loss: 3063.652587890625\n",
      "Epoch 0, iter 430, loss: 2764.39208984375\n",
      "Epoch 0, iter 440, loss: 2818.25439453125\n",
      "Epoch 0, iter 450, loss: 2729.37744140625\n",
      "Epoch 0, iter 460, loss: 2287.50927734375\n",
      "Epoch 0, iter 470, loss: 2380.731689453125\n",
      "Epoch 0, iter 480, loss: 2067.895263671875\n",
      "Epoch 0, iter 490, loss: 1955.76318359375\n",
      "Epoch 0, iter 500, loss: 1884.6290283203125\n",
      "Epoch 0, iter 510, loss: 1980.544189453125\n",
      "Epoch 0, iter 520, loss: 1820.4456787109375\n",
      "Epoch 0, iter 530, loss: 1437.173095703125\n",
      "Epoch 0, iter 540, loss: 1402.9412841796875\n",
      "Epoch 0, iter 550, loss: 1287.4744873046875\n",
      "Epoch 0, iter 560, loss: 1269.5113525390625\n",
      "Epoch 0, iter 570, loss: 1495.603271484375\n",
      "Epoch 0, iter 580, loss: 1135.50927734375\n",
      "Epoch 0, iter 590, loss: 1257.93701171875\n",
      "Epoch 0, iter 600, loss: 1118.3248291015625\n",
      "Epoch 0, iter 610, loss: 1724.4227294921875\n",
      "Epoch 0, iter 620, loss: 990.9928588867188\n",
      "Epoch 0, iter 630, loss: 888.510498046875\n",
      "Epoch 0, iter 640, loss: 1035.665771484375\n",
      "Epoch 0, iter 650, loss: 727.3289184570312\n",
      "Epoch 0, iter 660, loss: 677.1795654296875\n",
      "Epoch 0, iter 670, loss: 723.1918334960938\n",
      "Epoch 0, iter 680, loss: 679.666015625\n",
      "Epoch 0, iter 690, loss: 607.563720703125\n",
      "Epoch 0, iter 700, loss: 622.8663940429688\n",
      "Epoch 0, iter 710, loss: 555.9685668945312\n",
      "Epoch 0, iter 720, loss: 553.0218505859375\n",
      "Epoch 0, iter 730, loss: 428.7541198730469\n",
      "Epoch 0, iter 740, loss: 357.2422180175781\n",
      "Epoch 0, iter 750, loss: 425.5007019042969\n",
      "Epoch 0, iter 760, loss: 453.8479309082031\n",
      "Epoch 0, iter 770, loss: 252.56585693359375\n",
      "Epoch 0, iter 780, loss: 286.65740966796875\n",
      "Epoch 0, iter 790, loss: 297.9705810546875\n",
      "Epoch 0, iter 800, loss: 435.8641662597656\n",
      "Epoch 0, iter 810, loss: 292.0729675292969\n",
      "Epoch 0, iter 820, loss: 228.1162872314453\n",
      "Epoch 1, iter 0, loss: 217.22032165527344\n",
      "Epoch 1, iter 10, loss: 192.71234130859375\n",
      "Epoch 1, iter 20, loss: 272.85589599609375\n",
      "Epoch 1, iter 30, loss: 279.2919006347656\n",
      "Epoch 1, iter 40, loss: 164.3941650390625\n",
      "Epoch 1, iter 50, loss: 202.96949768066406\n",
      "Epoch 1, iter 60, loss: 184.33950805664062\n",
      "Epoch 1, iter 70, loss: 158.90301513671875\n",
      "Epoch 1, iter 80, loss: 128.3335418701172\n",
      "Epoch 1, iter 90, loss: 158.563720703125\n",
      "Epoch 1, iter 100, loss: 77.01407623291016\n",
      "Epoch 1, iter 110, loss: 123.91065216064453\n",
      "Epoch 1, iter 120, loss: 103.75703430175781\n",
      "Epoch 1, iter 130, loss: 80.30108642578125\n",
      "Epoch 1, iter 140, loss: 88.75162506103516\n",
      "Epoch 1, iter 150, loss: 105.45475006103516\n",
      "Epoch 1, iter 160, loss: 57.39509201049805\n",
      "Epoch 1, iter 170, loss: 101.48833465576172\n",
      "Epoch 1, iter 180, loss: 134.40838623046875\n",
      "Epoch 1, iter 190, loss: 100.41248321533203\n",
      "Epoch 1, iter 200, loss: 78.99007415771484\n",
      "Epoch 1, iter 210, loss: 56.065711975097656\n",
      "Epoch 1, iter 220, loss: 54.277198791503906\n",
      "Epoch 1, iter 230, loss: 58.985965728759766\n",
      "Epoch 1, iter 240, loss: 70.99605560302734\n",
      "Epoch 1, iter 250, loss: 78.17923736572266\n",
      "Epoch 1, iter 260, loss: 52.075382232666016\n",
      "Epoch 1, iter 270, loss: 194.06793212890625\n",
      "Epoch 1, iter 280, loss: 44.819313049316406\n",
      "Epoch 1, iter 290, loss: 46.39103698730469\n",
      "Epoch 1, iter 300, loss: 85.12959289550781\n",
      "Epoch 1, iter 310, loss: 67.81874084472656\n",
      "Epoch 1, iter 320, loss: 42.95940017700195\n",
      "Epoch 1, iter 330, loss: 65.10733795166016\n",
      "Epoch 1, iter 340, loss: 78.45543670654297\n",
      "Epoch 1, iter 350, loss: 46.91033172607422\n",
      "Epoch 1, iter 360, loss: 145.25730895996094\n",
      "Epoch 1, iter 370, loss: 34.4911003112793\n",
      "Epoch 1, iter 380, loss: 48.465538024902344\n",
      "Epoch 1, iter 390, loss: 48.600074768066406\n",
      "Epoch 1, iter 400, loss: 191.2849578857422\n",
      "Epoch 1, iter 410, loss: 94.9251937866211\n",
      "Epoch 1, iter 420, loss: 59.1872444152832\n",
      "Epoch 1, iter 430, loss: 92.54824829101562\n",
      "Epoch 1, iter 440, loss: 99.07862091064453\n",
      "Epoch 1, iter 450, loss: 31.25655746459961\n",
      "Epoch 1, iter 460, loss: 53.02687072753906\n",
      "Epoch 1, iter 470, loss: 62.418067932128906\n",
      "Epoch 1, iter 480, loss: 76.54026794433594\n",
      "Epoch 1, iter 490, loss: 99.10813903808594\n",
      "Epoch 1, iter 500, loss: 57.96677017211914\n",
      "Epoch 1, iter 510, loss: 55.608009338378906\n",
      "Epoch 1, iter 520, loss: 67.09156799316406\n",
      "Epoch 1, iter 530, loss: 46.39125442504883\n",
      "Epoch 1, iter 540, loss: 35.759002685546875\n",
      "Epoch 1, iter 550, loss: 51.36709976196289\n",
      "Epoch 1, iter 560, loss: 56.19621276855469\n",
      "Epoch 1, iter 570, loss: 31.572832107543945\n",
      "Epoch 1, iter 580, loss: 48.02177429199219\n",
      "Epoch 1, iter 590, loss: 27.883060455322266\n",
      "Epoch 1, iter 600, loss: 35.723751068115234\n",
      "Epoch 1, iter 610, loss: 72.24441528320312\n",
      "Epoch 1, iter 620, loss: 50.1335334777832\n",
      "Epoch 1, iter 630, loss: 31.9747257232666\n",
      "Epoch 1, iter 640, loss: 38.68440628051758\n",
      "Epoch 1, iter 650, loss: 40.03745651245117\n",
      "Epoch 1, iter 660, loss: 157.03038024902344\n",
      "Epoch 1, iter 670, loss: 19.00029945373535\n",
      "Epoch 1, iter 680, loss: 39.76764678955078\n",
      "Epoch 1, iter 690, loss: 60.9801025390625\n",
      "Epoch 1, iter 700, loss: 82.19755554199219\n",
      "Epoch 1, iter 710, loss: 14.382782936096191\n",
      "Epoch 1, iter 720, loss: 125.20919036865234\n",
      "Epoch 1, iter 730, loss: 27.96718406677246\n",
      "Epoch 1, iter 740, loss: 30.68785858154297\n",
      "Epoch 1, iter 750, loss: 45.53910827636719\n",
      "Epoch 1, iter 760, loss: 26.385969161987305\n",
      "Epoch 1, iter 770, loss: 19.46217155456543\n",
      "Epoch 1, iter 780, loss: 44.58525466918945\n",
      "Epoch 1, iter 790, loss: 27.14547348022461\n",
      "Epoch 1, iter 800, loss: 19.259620666503906\n",
      "Epoch 1, iter 810, loss: 44.82678985595703\n",
      "Epoch 1, iter 820, loss: 34.27387237548828\n",
      "Epoch 2, iter 0, loss: 61.05963134765625\n",
      "Epoch 2, iter 10, loss: 21.022008895874023\n",
      "Epoch 2, iter 20, loss: 74.94810485839844\n",
      "Epoch 2, iter 30, loss: 41.5836181640625\n",
      "Epoch 2, iter 40, loss: 41.06356430053711\n",
      "Epoch 2, iter 50, loss: 15.16634750366211\n",
      "Epoch 2, iter 60, loss: 39.54112243652344\n",
      "Epoch 2, iter 70, loss: 54.9644889831543\n",
      "Epoch 2, iter 80, loss: 29.746177673339844\n",
      "Epoch 2, iter 90, loss: 46.43307876586914\n",
      "Epoch 2, iter 100, loss: 16.648481369018555\n",
      "Epoch 2, iter 110, loss: 15.098396301269531\n",
      "Epoch 2, iter 120, loss: 58.032169342041016\n",
      "Epoch 2, iter 130, loss: 42.65278625488281\n",
      "Epoch 2, iter 140, loss: 46.30803680419922\n",
      "Epoch 2, iter 150, loss: 17.45220184326172\n",
      "Epoch 2, iter 160, loss: 53.133583068847656\n",
      "Epoch 2, iter 170, loss: 33.529319763183594\n",
      "Epoch 2, iter 180, loss: 25.943504333496094\n",
      "Epoch 2, iter 190, loss: 30.164634704589844\n",
      "Epoch 2, iter 200, loss: 27.315723419189453\n",
      "Epoch 2, iter 210, loss: 26.208017349243164\n",
      "Epoch 2, iter 220, loss: 23.410194396972656\n",
      "Epoch 2, iter 230, loss: 36.73420333862305\n",
      "Epoch 2, iter 240, loss: 14.386409759521484\n",
      "Epoch 2, iter 250, loss: 49.79085922241211\n",
      "Epoch 2, iter 260, loss: 15.153865814208984\n",
      "Epoch 2, iter 270, loss: 28.003158569335938\n",
      "Epoch 2, iter 280, loss: 36.24555587768555\n",
      "Epoch 2, iter 290, loss: 96.15645599365234\n",
      "Epoch 2, iter 300, loss: 39.61595153808594\n",
      "Epoch 2, iter 310, loss: 23.50292205810547\n",
      "Epoch 2, iter 320, loss: 86.64002990722656\n",
      "Epoch 2, iter 330, loss: 37.1101188659668\n",
      "Epoch 2, iter 340, loss: 31.834352493286133\n",
      "Epoch 2, iter 350, loss: 20.678125381469727\n",
      "Epoch 2, iter 360, loss: 55.92607879638672\n",
      "Epoch 2, iter 370, loss: 44.04016876220703\n",
      "Epoch 2, iter 380, loss: 10.511489868164062\n",
      "Epoch 2, iter 390, loss: 38.448158264160156\n",
      "Epoch 2, iter 400, loss: 32.6646842956543\n",
      "Epoch 2, iter 410, loss: 52.15217208862305\n",
      "Epoch 2, iter 420, loss: 29.54692840576172\n",
      "Epoch 2, iter 430, loss: 35.965965270996094\n",
      "Epoch 2, iter 440, loss: 24.6954288482666\n",
      "Epoch 2, iter 450, loss: 21.390840530395508\n",
      "Epoch 2, iter 460, loss: 26.260927200317383\n",
      "Epoch 2, iter 470, loss: 19.618946075439453\n",
      "Epoch 2, iter 480, loss: 20.396419525146484\n",
      "Epoch 2, iter 490, loss: 36.85073471069336\n",
      "Epoch 2, iter 500, loss: 56.127601623535156\n",
      "Epoch 2, iter 510, loss: 12.533724784851074\n",
      "Epoch 2, iter 520, loss: 26.39217185974121\n",
      "Epoch 2, iter 530, loss: 24.442649841308594\n",
      "Epoch 2, iter 540, loss: 19.489965438842773\n",
      "Epoch 2, iter 550, loss: 16.293476104736328\n",
      "Epoch 2, iter 560, loss: 51.90123748779297\n",
      "Epoch 2, iter 570, loss: 71.76201629638672\n",
      "Epoch 2, iter 580, loss: 22.398283004760742\n",
      "Epoch 2, iter 590, loss: 13.201818466186523\n",
      "Epoch 2, iter 600, loss: 47.17314529418945\n",
      "Epoch 2, iter 610, loss: 41.88139343261719\n",
      "Epoch 2, iter 620, loss: 32.30276107788086\n",
      "Epoch 2, iter 630, loss: 15.347468376159668\n",
      "Epoch 2, iter 640, loss: 35.71720886230469\n",
      "Epoch 2, iter 650, loss: 81.972412109375\n",
      "Epoch 2, iter 660, loss: 29.58974838256836\n",
      "Epoch 2, iter 670, loss: 15.680562019348145\n",
      "Epoch 2, iter 680, loss: 24.51390838623047\n",
      "Epoch 2, iter 690, loss: 23.714872360229492\n",
      "Epoch 2, iter 700, loss: 12.330394744873047\n",
      "Epoch 2, iter 710, loss: 5.532158374786377\n",
      "Epoch 2, iter 720, loss: 25.4368839263916\n",
      "Epoch 2, iter 730, loss: 58.32437515258789\n",
      "Epoch 2, iter 740, loss: 6.387833118438721\n",
      "Epoch 2, iter 750, loss: 15.377556800842285\n",
      "Epoch 2, iter 760, loss: 27.951618194580078\n",
      "Epoch 2, iter 770, loss: 21.776309967041016\n",
      "Epoch 2, iter 780, loss: 16.231351852416992\n",
      "Epoch 2, iter 790, loss: 59.31092071533203\n",
      "Epoch 2, iter 800, loss: 13.610651016235352\n",
      "Epoch 2, iter 810, loss: 12.128209114074707\n",
      "Epoch 2, iter 820, loss: 12.675341606140137\n",
      "Epoch 3, iter 0, loss: 29.166797637939453\n",
      "Epoch 3, iter 10, loss: 81.31317138671875\n",
      "Epoch 3, iter 20, loss: 52.247562408447266\n",
      "Epoch 3, iter 30, loss: 25.054004669189453\n",
      "Epoch 3, iter 40, loss: 12.875482559204102\n",
      "Epoch 3, iter 50, loss: 19.484943389892578\n",
      "Epoch 3, iter 60, loss: 21.11488151550293\n",
      "Epoch 3, iter 70, loss: 13.429829597473145\n",
      "Epoch 3, iter 80, loss: 10.150115013122559\n",
      "Epoch 3, iter 90, loss: 39.21293640136719\n",
      "Epoch 3, iter 100, loss: 13.290304183959961\n",
      "Epoch 3, iter 110, loss: 12.422410011291504\n",
      "Epoch 3, iter 120, loss: 9.21009349822998\n",
      "Epoch 3, iter 130, loss: 24.871448516845703\n",
      "Epoch 3, iter 140, loss: 12.225556373596191\n",
      "Epoch 3, iter 150, loss: 211.80226135253906\n",
      "Epoch 3, iter 160, loss: 30.09769058227539\n",
      "Epoch 3, iter 170, loss: 20.16693687438965\n",
      "Epoch 3, iter 180, loss: 17.828527450561523\n",
      "Epoch 3, iter 190, loss: 21.908021926879883\n",
      "Epoch 3, iter 200, loss: 28.5411319732666\n",
      "Epoch 3, iter 210, loss: 52.366233825683594\n",
      "Epoch 3, iter 220, loss: 29.590883255004883\n",
      "Epoch 3, iter 230, loss: 10.210942268371582\n",
      "Epoch 3, iter 240, loss: 61.19081497192383\n",
      "Epoch 3, iter 250, loss: 26.59088897705078\n",
      "Epoch 3, iter 260, loss: 39.79424285888672\n",
      "Epoch 3, iter 270, loss: 14.275345802307129\n",
      "Epoch 3, iter 280, loss: 20.355438232421875\n",
      "Epoch 3, iter 290, loss: 17.36871337890625\n",
      "Epoch 3, iter 300, loss: 24.64316749572754\n",
      "Epoch 3, iter 310, loss: 13.55578899383545\n",
      "Epoch 3, iter 320, loss: 34.79362487792969\n",
      "Epoch 3, iter 330, loss: 13.316193580627441\n",
      "Epoch 3, iter 340, loss: 13.137582778930664\n",
      "Epoch 3, iter 350, loss: 9.157694816589355\n",
      "Epoch 3, iter 360, loss: 5.450995445251465\n",
      "Epoch 3, iter 370, loss: 12.693041801452637\n",
      "Epoch 3, iter 380, loss: 10.215829849243164\n",
      "Epoch 3, iter 390, loss: 24.60049819946289\n",
      "Epoch 3, iter 400, loss: 15.417864799499512\n",
      "Epoch 3, iter 410, loss: 8.186798095703125\n",
      "Epoch 3, iter 420, loss: 12.193512916564941\n",
      "Epoch 3, iter 430, loss: 4.825242519378662\n",
      "Epoch 3, iter 440, loss: 25.495908737182617\n",
      "Epoch 3, iter 450, loss: 29.42458152770996\n",
      "Epoch 3, iter 460, loss: 9.619672775268555\n",
      "Epoch 3, iter 470, loss: 60.092960357666016\n",
      "Epoch 3, iter 480, loss: 215.80511474609375\n",
      "Epoch 3, iter 490, loss: 35.75849151611328\n",
      "Epoch 3, iter 500, loss: 11.001551628112793\n",
      "Epoch 3, iter 510, loss: 9.008398056030273\n",
      "Epoch 3, iter 520, loss: 13.5205717086792\n",
      "Epoch 3, iter 530, loss: 26.220088958740234\n",
      "Epoch 3, iter 540, loss: 23.03668785095215\n",
      "Epoch 3, iter 550, loss: 24.482099533081055\n",
      "Epoch 3, iter 560, loss: 9.241490364074707\n",
      "Epoch 3, iter 570, loss: 9.224522590637207\n",
      "Epoch 3, iter 580, loss: 11.93161678314209\n",
      "Epoch 3, iter 590, loss: 63.32646942138672\n",
      "Epoch 3, iter 600, loss: 238.42544555664062\n",
      "Epoch 3, iter 610, loss: 10.068449020385742\n",
      "Epoch 3, iter 620, loss: 65.38893127441406\n",
      "Epoch 3, iter 630, loss: 25.33619499206543\n",
      "Epoch 3, iter 640, loss: 9.738905906677246\n",
      "Epoch 3, iter 650, loss: 19.85447120666504\n",
      "Epoch 3, iter 660, loss: 28.726884841918945\n",
      "Epoch 3, iter 670, loss: 11.370363235473633\n",
      "Epoch 3, iter 680, loss: 6.724879741668701\n",
      "Epoch 3, iter 690, loss: 38.585113525390625\n",
      "Epoch 3, iter 700, loss: 6.117429733276367\n",
      "Epoch 3, iter 710, loss: 14.524267196655273\n",
      "Epoch 3, iter 720, loss: 7.451611042022705\n",
      "Epoch 3, iter 730, loss: 21.839452743530273\n",
      "Epoch 3, iter 740, loss: 18.778303146362305\n",
      "Epoch 3, iter 750, loss: 15.496142387390137\n",
      "Epoch 3, iter 760, loss: 16.08141326904297\n",
      "Epoch 3, iter 770, loss: 8.438348770141602\n",
      "Epoch 3, iter 780, loss: 6.260121822357178\n",
      "Epoch 3, iter 790, loss: 8.806270599365234\n",
      "Epoch 3, iter 800, loss: 4.992058753967285\n",
      "Epoch 3, iter 810, loss: 18.70047950744629\n",
      "Epoch 3, iter 820, loss: 8.040871620178223\n",
      "Epoch 4, iter 0, loss: 17.004291534423828\n",
      "Epoch 4, iter 10, loss: 8.148178100585938\n",
      "Epoch 4, iter 20, loss: 11.857094764709473\n",
      "Epoch 4, iter 30, loss: 17.248693466186523\n",
      "Epoch 4, iter 40, loss: 8.820571899414062\n",
      "Epoch 4, iter 50, loss: 27.718624114990234\n",
      "Epoch 4, iter 60, loss: 7.402303695678711\n",
      "Epoch 4, iter 70, loss: 7.417088031768799\n",
      "Epoch 4, iter 80, loss: 9.957696914672852\n",
      "Epoch 4, iter 90, loss: 43.038150787353516\n",
      "Epoch 4, iter 100, loss: 14.48934555053711\n",
      "Epoch 4, iter 110, loss: 5.066520690917969\n",
      "Epoch 4, iter 120, loss: 12.196210861206055\n",
      "Epoch 4, iter 130, loss: 10.0423002243042\n",
      "Epoch 4, iter 140, loss: 8.742049217224121\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, (imgs,kps) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m      4\u001b[0m         imgs \u001b[38;5;241m=\u001b[39m imgs\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      5\u001b[0m         kps \u001b[38;5;241m=\u001b[39m kps\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[41], line 23\u001b[0m, in \u001b[0;36mKeypointsDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     20\u001b[0m h,w \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m     22\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(img, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[0;32m---> 23\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransforms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m kps \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkps\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m     25\u001b[0m kps \u001b[38;5;241m=\u001b[39m kps\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torchvision/transforms/transforms.py:361\u001b[0m, in \u001b[0;36mResize.forward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m    354\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;124;03m        img (PIL Image or Tensor): Image to be scaled.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;124;03m        PIL Image or Tensor: Rescaled image.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 361\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mantialias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torchvision/transforms/functional.py:490\u001b[0m, in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[1;32m    488\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnti-alias option is always applied for PIL Image input. Argument antialias is ignored.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    489\u001b[0m     pil_interpolation \u001b[38;5;241m=\u001b[39m pil_modes_mapping[interpolation]\n\u001b[0;32m--> 490\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF_pil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpil_interpolation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F_t\u001b[38;5;241m.\u001b[39mresize(img, size\u001b[38;5;241m=\u001b[39moutput_size, interpolation\u001b[38;5;241m=\u001b[39minterpolation\u001b[38;5;241m.\u001b[39mvalue, antialias\u001b[38;5;241m=\u001b[39mantialias)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torchvision/transforms/_functional_pil.py:250\u001b[0m, in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(size, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(size) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot inappropriate size arg: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 250\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/PIL/Image.py:2192\u001b[0m, in \u001b[0;36mImage.resize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   2184\u001b[0m             \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mreduce(\u001b[38;5;28mself\u001b[39m, factor, box\u001b[38;5;241m=\u001b[39mreduce_box)\n\u001b[1;32m   2185\u001b[0m         box \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2186\u001b[0m             (box[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_x,\n\u001b[1;32m   2187\u001b[0m             (box[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_y,\n\u001b[1;32m   2188\u001b[0m             (box[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_x,\n\u001b[1;32m   2189\u001b[0m             (box[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_y,\n\u001b[1;32m   2190\u001b[0m         )\n\u001b[0;32m-> 2192\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbox\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs=20\n",
    "for epoch in range(epochs):\n",
    "    for i, (imgs,kps) in enumerate(train_loader):\n",
    "        imgs = imgs.to(device)\n",
    "        kps = kps.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, kps)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, iter {i}, loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████| 829/829 [02:33<00:00,  5.39it/s, loss=16.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 finished with average loss: 16.925512610931303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|██████████| 829/829 [02:33<00:00,  5.39it/s, loss=11.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2 finished with average loss: 11.772661282228187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|██████████| 829/829 [02:33<00:00,  5.40it/s, loss=11.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3 finished with average loss: 11.134456778392286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20:  41%|████      | 338/829 [01:02<01:31,  5.38it/s, loss=11.9]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m      8\u001b[0m progress_bar \u001b[38;5;241m=\u001b[39m tqdm(\u001b[38;5;28menumerate\u001b[39m(train_loader), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_loader), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (imgs, kps) \u001b[38;5;129;01min\u001b[39;00m progress_bar:\n\u001b[1;32m     11\u001b[0m     imgs \u001b[38;5;241m=\u001b[39m imgs\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     12\u001b[0m     kps \u001b[38;5;241m=\u001b[39m kps\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[41], line 19\u001b[0m, in \u001b[0;36mKeypointsDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m     18\u001b[0m     item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[idx]\n\u001b[0;32m---> 19\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_dir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mitem\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.png\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     h,w \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m     22\u001b[0m     img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(img, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    progress_bar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch + 1}/{epochs}\")\n",
    "\n",
    "    for i, (imgs, kps) in progress_bar:\n",
    "        imgs = imgs.to(device)\n",
    "        kps = kps.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, kps)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        avg_loss = running_loss / (i + 1)\n",
    "\n",
    "        progress_bar.set_postfix(loss=avg_loss)\n",
    "\n",
    "    print(f\"\\nEpoch {epoch + 1} Train Loss: {avg_loss}\")\n",
    "    \n",
    "    # 验证模型在验证集上的性能\n",
    "    model.eval()\n",
    "    valid_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for imgs, kps in valid_loader:\n",
    "            imgs = imgs.to(device)\n",
    "            kps = kps.to(device)\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, kps)\n",
    "            valid_loss += loss.item()\n",
    "    valid_loss /= len(valid_loader)\n",
    "    print(f\"Val Loss: {valid_loss:.4f}\")\n",
    "\n",
    "    # 保存最优模型\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        current_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        best_model_path = f\"keypoints_model_best_{current_time}.pth\"\n",
    "        torch.save(model.state_dict(), os.path.join('./models', best_model_path))\n",
    "        print(f\"Best model saved as {best_model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints_model_20240617_030821.pth\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datetime import datetime\n",
    "\n",
    "# 获取当前时间并格式化为字符串\n",
    "current_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# 构建文件名\n",
    "filename = f\"keypoints_model_{current_time}.pth\"\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as keypoints_model_20240617_030821.pth\n"
     ]
    }
   ],
   "source": [
    "# 保存模型\n",
    "torch.save(model.state_dict(), f'./models/{filename}')\n",
    "\n",
    "print(f\"Model saved as {filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
